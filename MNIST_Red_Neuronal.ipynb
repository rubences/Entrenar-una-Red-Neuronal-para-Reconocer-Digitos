{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda21c4c",
   "metadata": {},
   "source": [
    "# Tu Misión: Entrenar una Red Neuronal para Reconocer Dígitos\n",
    "\n",
    "¡Bienvenido/a al Desafío MNIST! En este notebook aprenderás a construir, entrenar y evaluar una red neuronal profunda capaz de reconocer dígitos escritos a mano. Utilizaremos Python y TensorFlow/Keras para abordar este reto clásico de Machine Learning y Deep Learning.\n",
    "\n",
    "**Fases del proyecto:**\n",
    "1. Configuración del entorno y carga de librerías\n",
    "2. Carga y exploración del dataset MNIST\n",
    "3. Visualización de imágenes del dataset\n",
    "4. Preprocesamiento de los datos\n",
    "5. Construcción de la arquitectura del modelo\n",
    "6. Visualización del resumen del modelo\n",
    "7. Compilación y entrenamiento del modelo\n",
    "8. Evaluación del modelo en el conjunto de prueba\n",
    "9. Visualización de gráficos de precisión y pérdida\n",
    "10. Análisis de sobreajuste y preguntas de reflexión\n",
    "\n",
    "Cada sección incluye explicaciones y preguntas de análisis para profundizar tu comprensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d14171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración del Entorno y Carga de Librerías\n",
    "# Importamos las librerías necesarias para el proyecto.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carga y Exploración del Dataset MNIST\n",
    "# Cargamos el dataset MNIST usando Keras y verificamos las dimensiones de los datos.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "print(f\"Imágenes de entrenamiento: {x_train.shape}\")\n",
    "print(f\"Imágenes de prueba: {x_test.shape}\")\n",
    "print(f\"Etiquetas de entrenamiento: {y_train.shape}\")\n",
    "print(f\"Etiquetas de prueba: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualización de Imágenes del Dataset\n",
    "# Mostramos 5 imágenes diferentes del conjunto de entrenamiento junto con sus etiquetas.\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_train[i], cmap='gray')\n",
    "    axes[i].set_title(f\"Etiqueta: {y_train[i]}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacb5ab",
   "metadata": {},
   "source": [
    "### Pregunta de Análisis 1\n",
    "¿Encuentras variaciones en la escritura de un mismo número (por ejemplo, el \"7\" o el \"2\")? ¿Por qué crees que estas variaciones representan un desafío para un algoritmo?\n",
    "\n",
    "*Respuesta:* \n",
    "Sí, se observan variaciones significativas en la forma en que diferentes personas escriben el mismo número. Estas diferencias pueden incluir grosor, inclinación, tamaño y estilo. Para un algoritmo, estas variaciones dificultan la tarea de identificar patrones consistentes, ya que debe aprender a reconocer la esencia del número independientemente de las diferencias individuales en la escritura. Esto hace que el problema sea complejo y requiera modelos robustos capaces de generalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef12930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocesamiento de los Datos\n",
    "# Normalizamos los valores de los píxeles, aplanamos las imágenes y realizamos one-hot encoding de las etiquetas.\n",
    "x_train_norm = x_train.astype('float32') / 255.0\n",
    "x_test_norm = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train_flat = x_train_norm.reshape(-1, 28*28)\n",
    "x_test_flat = x_test_norm.reshape(-1, 28*28)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Datos de entrenamiento normalizados y aplanados: {x_train_flat.shape}\")\n",
    "print(f\"Etiquetas codificadas (one-hot): {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7fb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Construcción de la Arquitectura del Modelo\n",
    "# Definimos la red neuronal usando la API Sequential de Keras.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc591259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualización del Resumen del Modelo\n",
    "# Mostramos la arquitectura y el número de parámetros del modelo.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bad084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Compilación y Entrenamiento del Modelo\n",
    "# Compilamos el modelo y lo entrenamos usando los datos preprocesados.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_flat, y_train_cat,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Evaluación del Modelo en el Conjunto de Prueba\n",
    "# Evaluamos el modelo usando los datos de prueba y reportamos la precisión final.\n",
    "test_loss, test_acc = model.evaluate(x_test_flat, y_test_cat, verbose=2)\n",
    "print(f\"Precisión final en el conjunto de prueba: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Visualización de Gráficos de Precisión y Pérdida\n",
    "# Graficamos la precisión y la pérdida de entrenamiento y validación a lo largo de las épocas.\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión del Modelo')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida del Modelo')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936c4d7",
   "metadata": {},
   "source": [
    "### Pregunta de Análisis 2\n",
    "¿La precisión de entrenamiento sigue mejorando mientras que la de validación se estanca o empeora? ¿La pérdida de entrenamiento disminuye mientras que la de validación aumenta? Si respondiste sí, estás viendo un claro signo de sobreajuste.\n",
    "\n",
    "*Respuesta:* \n",
    "Si los gráficos muestran que la precisión de entrenamiento sigue aumentando pero la de validación se mantiene o disminuye, y la pérdida de validación aumenta mientras la de entrenamiento baja, esto indica sobreajuste. El modelo está \"memorizando\" los datos de entrenamiento y pierde capacidad de generalización sobre datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b05c0",
   "metadata": {},
   "source": [
    "### Pregunta de Análisis 3\n",
    "Explica con tus propias palabras qué es el sobreajuste. ¿Por qué es un problema que el modelo funcione perfectamente con los datos de entrenamiento pero no tan bien con los de validación?\n",
    "\n",
    "*Respuesta:* \n",
    "El sobreajuste ocurre cuando un modelo aprende demasiado bien los detalles y el ruido de los datos de entrenamiento, perdiendo la capacidad de generalizar a datos nuevos. Es un problema porque el objetivo de un modelo de Machine Learning es funcionar bien con datos que nunca ha visto. Si el modelo solo es preciso con los datos de entrenamiento, su utilidad en el mundo real es limitada.\n",
    "\n",
    "**Estrategias para reducir el sobreajuste:**\n",
    "- **Dropout:** Consiste en desactivar aleatoriamente algunas neuronas durante el entrenamiento, lo que obliga al modelo a no depender de rutas específicas y mejora la generalización.\n",
    "- **Regularización L2:** Penaliza los pesos grandes en la función de pérdida, ayudando a que el modelo sea más simple y menos propenso a memorizar el ruido.\n",
    "- **Aumentar el dataset:** Más datos permiten que el modelo aprenda patrones más generales y robustos, reduciendo el riesgo de sobreajuste.\n",
    "\n",
    "Estas estrategias funcionan porque ayudan al modelo a enfocarse en patrones generales y no en detalles específicos de los datos de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
